{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a942766",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf3566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd7d55",
   "metadata": {},
   "source": [
    "# Paths for annotations and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a23e0cd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m BASE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m))\n\u001b[0;32m      2\u001b[0m ANNOTATIONS_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_annotations.coco.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m OUTPUT_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "ANNOTATIONS_PATH = os.path.join(BASE_DIR, 'annotations', '_annotations.coco.json')\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, 'output')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8feae",
   "metadata": {},
   "source": [
    "# Color map for each category from RoboFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c73144",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_MAP = {\n",
    "                'agua': (61, 61, 245),\n",
    "                'erosao': (221, 255, 51),\n",
    "                'trinca': (252, 128, 7),\n",
    "                'ruptura': (36, 179, 83)\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff9c7a",
   "metadata": {},
   "source": [
    "# COCO file initialization and category mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(ANNOTATIONS_PATH)\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "id_to_name = {cat['id']: cat['name'].lower() for cat in categories}\n",
    "print(\"\\nDetected categories:\")\n",
    "for k, v in id_to_name.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf141416",
   "metadata": {},
   "source": [
    "# Generate masks for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1160735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_id in coco.imgs:\n",
    "    img_info = coco.imgs[img_id]\n",
    "    print(f\"\\nGenerating mask for: {img_info['file_name']}\")\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    height, width = img_info['height'], img_info['width']\n",
    "    colored_mask = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    for ann in anns:\n",
    "        if ann.get('iscrowd', 0) == 1:\n",
    "            continue\n",
    "        if not ann.get('segmentation'):\n",
    "            continue\n",
    "        cat_name = id_to_name.get(ann['category_id'])\n",
    "        if cat_name not in COLOR_MAP:\n",
    "            continue\n",
    "        ann_mask = coco.annToMask(ann)\n",
    "        if ann_mask.sum() == 0:\n",
    "            continue\n",
    "        colored_mask[ann_mask == 1] = COLOR_MAP[cat_name]\n",
    "    mask_name = os.path.splitext(img_info['file_name'])[0] + '.png'\n",
    "    output_path = os.path.join(OUTPUT_DIR, mask_name)\n",
    "    Image.fromarray(colored_mask).save(output_path)\n",
    "    print(f\"‚úî mask saved at: {output_path}\")\n",
    "print(\"\\nüéâ Processing completed! All masks have been generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbffc64",
   "metadata": {},
   "source": [
    "# Count unique colors in the generated masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176a046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_masks = OUTPUT_DIR\n",
    "arquivos = get_image_files(path_masks)\n",
    "print(f\"üìÇ Reading {len(arquivos)} masks... please wait.\")\n",
    "\n",
    "# Contadores para armazenar as cores encontradas\n",
    "cores_encontradas = Counter()\n",
    "tipos_arquivos = Counter()\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    # Abre a imagem\n",
    "    img = PIL.Image.open(arquivo)\n",
    "    arr = np.array(img)\n",
    "    \n",
    "    # Verifica se √© Grayscale (2D) ou RGB (3D)\n",
    "    if len(arr.shape) == 2:\n",
    "        tipos_arquivos['Grayscale (2D)'] += 1\n",
    "        # Pega valores √∫nicos\n",
    "        uniques = np.unique(arr)\n",
    "        cores_encontradas.update(uniques)\n",
    "        \n",
    "    elif len(arr.shape) == 3:\n",
    "        tipos_arquivos['RGB (3D)'] += 1\n",
    "        # Transforma a matriz 3D em uma lista de pixels (R, G, B)\n",
    "        # Ex: transforma (1024, 1024, 3) em (1048576, 3)\n",
    "        pixels = arr.reshape(-1, 3)\n",
    "        # Pega as linhas √∫nicas (cores √∫nicas)\n",
    "        uniques = np.unique(pixels, axis=0)\n",
    "        # Adiciona ao contador (convertendo para tupla para poder contar)\n",
    "        cores_encontradas.update([tuple(p) for p in uniques])\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"üìä Statistics\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"File types found: {dict(tipos_arquivos)}\")\n",
    "print(\"\\nüé® THE 10 MOST COMMON COLORS (Format: Color -> How many images have this color):\")\n",
    "for cor, contagem in cores_encontradas.most_common():\n",
    "    print(f\"   üëâ Color: {cor} \\t(Appears in pixels of various images)\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908336e",
   "metadata": {},
   "source": [
    "# Build a pixel map for Fast AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f17c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL.Image\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# --- CONFIGURA√á√ÉO ---\n",
    "PATH_MASKS = Path(\"caminho/para/suas/mascaras\")  # <--- COLOQUE O CAMINHO AQUI\n",
    "# Se tiver cores que voc√™ J√Å SABE o nome, coloque aqui para ele usar o nome certo.\n",
    "# Se n√£o souber, deixe vazio, ele vai criar nomes como \"Classe_1\", \"Classe_2\".\n",
    "NOMES_CONHECIDOS = {\n",
    "    (0, 0, 0): \"Background\",\n",
    "    (61, 61, 245): \"Agua\",     # Azul\n",
    "    (221, 255, 51): \"Erosao\",  # Amarelo\n",
    "}\n",
    "# --------------------\n",
    "\n",
    "def analisar_dataset(path_masks):\n",
    "    arquivos = list(path_masks.glob(\"*.png\")) + list(path_masks.glob(\"*.jpg\")) # Ajuste extens√µes se precisar\n",
    "    print(f\"üìÇ Lendo {len(arquivos)} m√°scaras...\")\n",
    "\n",
    "    todas_cores = Counter()\n",
    "\n",
    "    for arquivo in arquivos:\n",
    "        img = PIL.Image.open(arquivo)\n",
    "        arr = np.array(img)\n",
    "\n",
    "        # Se for 3D (RGB)\n",
    "        if len(arr.shape) == 3:\n",
    "            pixels = arr.reshape(-1, 3)\n",
    "            # Pega cores √∫nicas dessa imagem\n",
    "            cores_img = np.unique(pixels, axis=0)\n",
    "            # Adiciona ao contador geral (transforma em tupla para poder contar)\n",
    "            todas_cores.update([tuple(c) for c in cores_img])\n",
    "        \n",
    "        # Se for 2D (Grayscale/Indexed)\n",
    "        elif len(arr.shape) == 2:\n",
    "            cores_img = np.unique(arr)\n",
    "            todas_cores.update(cores_img)\n",
    "\n",
    "    return todas_cores\n",
    "\n",
    "# --- EXECU√á√ÉO ---\n",
    "cores_encontradas = analisar_dataset(PATH_MASKS)\n",
    "\n",
    "# Filtra ru√≠do (cores que aparecem em menos de 1000 pixels no total do dataset)\n",
    "# Isso evita que um pixelzinho borrado crie uma classe nova errada\n",
    "LIMITE_RUIDO = 1000 \n",
    "cores_validas = [c for c, qtd in cores_encontradas.items() if qtd > LIMITE_RUIDO]\n",
    "\n",
    "# --- ORDENA√á√ÉO INTELIGENTE ---\n",
    "# 1. Background sempre primeiro (0,0,0) ou 0\n",
    "# 2. Depois, ordena por frequ√™ncia (quem tem mais pixels ganha ID menor)\n",
    "#    OU ordena fixo se voc√™ quiser garantir consist√™ncia sempre.\n",
    "\n",
    "# Vamos separar o background\n",
    "tem_bg_rgb = (0,0,0) in cores_validas\n",
    "tem_bg_gray = 0 in cores_validas\n",
    "\n",
    "lista_final = []\n",
    "\n",
    "# Adiciona Background primeiro\n",
    "if tem_bg_rgb:\n",
    "    lista_final.append((0,0,0))\n",
    "    cores_validas.remove((0,0,0))\n",
    "elif tem_bg_gray:\n",
    "    lista_final.append(0)\n",
    "    cores_validas.remove(0)\n",
    "\n",
    "# Ordena o resto pela quantidade de pixels (do mais comum para o menos comum)\n",
    "# Isso explica pq Eros√£o pode estar vindo antes da √Ågua: ela pode ter mais pixels no total!\n",
    "resto_ordenado = sorted(cores_validas, key=lambda x: cores_encontradas[x], reverse=True)\n",
    "lista_final.extend(resto_ordenado)\n",
    "\n",
    "# --- GERAR O CODIGO ---\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"‚úÖ AQUI EST√Å SEU MAPEAMENTO FINAL\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "pixel_map = {}\n",
    "meus_codes = []\n",
    "\n",
    "for idx, cor in enumerate(lista_final):\n",
    "    # Tenta achar o nome\n",
    "    nome = NOMES_CONHECIDOS.get(cor, f\"Classe_{idx}\")\n",
    "    \n",
    "    pixel_map[cor] = idx\n",
    "    meus_codes.append(nome)\n",
    "    \n",
    "    print(f\"ID {idx}: {str(cor):<15} -> {nome}\")\n",
    "\n",
    "print(\"\\nCOPIE E COLE ISSO NO SEU CODIGO DE TREINO:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"pixel_map = {pixel_map}\")\n",
    "print(f\"meus_codes = {meus_codes}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if len(cores_encontradas) > len(lista_final):\n",
    "    print(f\"\\n‚ö†Ô∏è  Aten√ß√£o: {len(cores_encontradas) - len(lista_final)} cores raras foram ignoradas como ru√≠do.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
